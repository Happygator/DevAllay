#!/usr/bin/env python3

import requests
from bs4 import BeautifulSoup
from typing import Optional

def download_images(url: str) -> None:
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    img_tags = soup.find_all('img', {'src': True})
    
    for img_tag in img_tags:
        img_url = img_tag['src']
        img_response = requests.get(img_url)
        img_name = img_url.split('/')[-1]
        
        with open(img_name, 'wb') as img_file:
            img_file.write(img_response.content)

def find_next_page_url(page_content: str) -> Optional[str]:
    soup = BeautifulSoup(page_content, 'html.parser')
    next_link = soup.find('a', text='Next Link')
    
    if next_link:
        return next_link['href']
    else:
        return None

if __name__ == '__main__':
    download_images('http://example.com')
